{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia Detection - Data Exploration\n",
    "\n",
    "This notebook explores the chest X-ray dataset for pneumonia detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from collections import Counter\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "data_dir = '../data/chest_xray'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# Count images in each category\n",
    "def count_images(directory):\n",
    "    counts = {}\n",
    "    for category in ['NORMAL', 'PNEUMONIA']:\n",
    "        category_path = os.path.join(directory, category)\n",
    "        if os.path.exists(category_path):\n",
    "            counts[category] = len(os.listdir(category_path))\n",
    "        else:\n",
    "            counts[category] = 0\n",
    "    return counts\n",
    "\n",
    "train_counts = count_images(train_dir)\n",
    "val_counts = count_images(val_dir)\n",
    "test_counts = count_images(test_dir)\n",
    "\n",
    "print(\"Dataset Distribution:\")\n",
    "print(f\"Training: {train_counts}\")\n",
    "print(f\"Validation: {val_counts}\")\n",
    "print(f\"Testing: {test_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "datasets = [('Training', train_counts), ('Validation', val_counts), ('Testing', test_counts)]\n",
    "\n",
    "for i, (name, counts) in enumerate(datasets):\n",
    "    categories = list(counts.keys())\n",
    "    values = list(counts.values())\n",
    "    \n",
    "    axes[i].bar(categories, values, color=['skyblue', 'lightcoral'])\n",
    "    axes[i].set_title(f'{name} Set Distribution')\n",
    "    axes[i].set_ylabel('Number of Images')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for j, v in enumerate(values):\n",
    "        axes[i].text(j, v + 10, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Images Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(data_dir, num_samples=4):\n",
    "    \"\"\"Display sample images from each category\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(16, 8))\n",
    "    \n",
    "    categories = ['NORMAL', 'PNEUMONIA']\n",
    "    \n",
    "    for i, category in enumerate(categories):\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        image_files = os.listdir(category_path)[:num_samples]\n",
    "        \n",
    "        for j, image_file in enumerate(image_files):\n",
    "            img_path = os.path.join(category_path, image_file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            axes[i, j].imshow(img, cmap='gray')\n",
    "            axes[i, j].set_title(f'{category}\\n{image_file}')\n",
    "            axes[i, j].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Chest X-Ray Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_sample_images(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Properties Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_properties(data_dir, sample_size=100):\n",
    "    \"\"\"Analyze image dimensions and properties\"\"\"\n",
    "    properties = {'category': [], 'width': [], 'height': [], 'aspect_ratio': [], 'file_size': []}\n",
    "    \n",
    "    for category in ['NORMAL', 'PNEUMONIA']:\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        image_files = os.listdir(category_path)[:sample_size]\n",
    "        \n",
    "        for image_file in image_files:\n",
    "            img_path = os.path.join(category_path, image_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                h, w = img.shape[:2]\n",
    "                file_size = os.path.getsize(img_path) / 1024  # KB\n",
    "                \n",
    "                properties['category'].append(category)\n",
    "                properties['width'].append(w)\n",
    "                properties['height'].append(h)\n",
    "                properties['aspect_ratio'].append(w/h)\n",
    "                properties['file_size'].append(file_size)\n",
    "    \n",
    "    return pd.DataFrame(properties)\n",
    "\n",
    "# Analyze properties\n",
    "df_props = analyze_image_properties(train_dir)\n",
    "print(\"Image Properties Summary:\")\n",
    "print(df_props.groupby('category').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize image properties\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Width distribution\n",
    "sns.boxplot(data=df_props, x='category', y='width', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Image Width Distribution')\n",
    "\n",
    "# Height distribution\n",
    "sns.boxplot(data=df_props, x='category', y='height', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Image Height Distribution')\n",
    "\n",
    "# Aspect ratio\n",
    "sns.boxplot(data=df_props, x='category', y='aspect_ratio', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Aspect Ratio Distribution')\n",
    "\n",
    "# File size\n",
    "sns.boxplot(data=df_props, x='category', y='file_size', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('File Size Distribution (KB)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_preprocessing_steps(image_path):\n",
    "    \"\"\"Show preprocessing steps on a sample image\"\"\"\n",
    "    # Read original image\n",
    "    img_original = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Resize\n",
    "    img_resized = cv2.resize(img_original, (224, 224))\n",
    "    \n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img_clahe = clahe.apply(img_resized)\n",
    "    \n",
    "    # Normalize\n",
    "    img_normalized = img_clahe.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Display all steps\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    images = [img_original, img_resized, img_clahe, img_normalized]\n",
    "    titles = ['Original', 'Resized (224x224)', 'CLAHE Applied', 'Normalized']\n",
    "    \n",
    "    for i, (img, title) in enumerate(zip(images, titles)):\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(title)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Image Preprocessing Pipeline', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show preprocessing for normal and pneumonia images\n",
    "normal_img = os.path.join(train_dir, 'NORMAL', os.listdir(os.path.join(train_dir, 'NORMAL'))[0])\n",
    "pneumonia_img = os.path.join(train_dir, 'PNEUMONIA', os.listdir(os.path.join(train_dir, 'PNEUMONIA'))[0])\n",
    "\n",
    "print(\"Normal X-Ray Preprocessing:\")\n",
    "show_preprocessing_steps(normal_img)\n",
    "\n",
    "print(\"\\nPneumonia X-Ray Preprocessing:\")\n",
    "show_preprocessing_steps(pneumonia_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel Intensity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pixel_intensities(data_dir, num_samples=20):\n",
    "    \"\"\"Analyze pixel intensity distributions\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    categories = ['NORMAL', 'PNEUMONIA']\n",
    "    colors = ['blue', 'red']\n",
    "    \n",
    "    for i, (category, color) in enumerate(zip(categories, colors)):\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        image_files = os.listdir(category_path)[:num_samples]\n",
    "        \n",
    "        all_intensities = []\n",
    "        \n",
    "        for image_file in image_files:\n",
    "            img_path = os.path.join(category_path, image_file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img_resized = cv2.resize(img, (224, 224))\n",
    "            all_intensities.extend(img_resized.flatten())\n",
    "        \n",
    "        # Plot histogram\n",
    "        axes[i].hist(all_intensities, bins=50, alpha=0.7, color=color, density=True)\n",
    "        axes[i].set_title(f'{category} - Pixel Intensity Distribution')\n",
    "        axes[i].set_xlabel('Pixel Intensity')\n",
    "        axes[i].set_ylabel('Density')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_pixel_intensities(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "1. **Dataset Imbalance**: The dataset shows class imbalance with more pneumonia cases than normal cases\n",
    "2. **Image Variability**: X-ray images have varying dimensions and file sizes\n",
    "3. **Preprocessing Impact**: CLAHE significantly improves contrast in chest X-rays\n",
    "4. **Pixel Patterns**: Normal and pneumonia X-rays show different intensity distributions\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Implement data augmentation to handle class imbalance\n",
    "2. Use transfer learning with pre-trained models\n",
    "3. Apply proper preprocessing pipeline\n",
    "4. Evaluate multiple model architectures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}